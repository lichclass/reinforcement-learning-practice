
**Objectives**
- Define the **Temporal Difference Learning**
- Define the **Temporal Difference Error**

**Temporal Difference**
- Updates estimates in an online (real-time) manner. 
- **TD vs MC:** Instead of updating after each episode (Monte Carlo), TD updates the values after each step.
- **Uses bootstrapping:** Instead of computing the full return, it updates based on an estimate of future rewards.

**Temporal Difference Integrations**
- Takes Monte Carlo's model-free advantage
- Takes Dynamic Programming's bootstrapping mechanisms

**Equation:**
$$
V(S_t) \leftarrow V(S_t) + \alpha[R_{t+1}+\gamma V(S_{t+1})-V(S_t)]
$$
- This variant of TD is called **TD(0)** because it updates based on a **single future step.**

**PSEUDOCODE**
![[Pasted image 20250228190002.png]]

****
**Cue**
- What is bootstrapping?
- What is the TD-error? ****

---
**Summary**
- **Temporal Difference Learning** - a way to incrementally estimate the return through bootstrapping.
- **TD-error:** $\delta_t = R_{t+1} + \gamma V(S_{t+1}-V(S_t))$
